{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2697b0a",
   "metadata": {},
   "source": [
    "# Dataset Cleaning and Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b58f63a",
   "metadata": {},
   "source": [
    "Check AIcrowd Notebook for detail analysis of the dataset: <br>\n",
    "https://www.aicrowd.com/showcase/food-recognition-benchmark-data-exploration-baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2d5572",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b327a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hub\n",
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe50e9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BUGGER_OFF=True\n",
      "Successfully logged in to Activeloop.\n"
     ]
    }
   ],
   "source": [
    "# Activeloop Settings\n",
    "%env BUGGER_OFF=True\n",
    "!activeloop reporting --off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1018005e",
   "metadata": {},
   "source": [
    "# Downloading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59e4a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please login here: \u001b[34m\u001b[1m\u001b[4mhttps://api.aicrowd.com/auth/yg-D7x7-l8m_vPSd-75V12PN0TL4D5t72oncWk4Pk14\u001b[0m\n",
      "Opening in existing browser session.\n",
      "[166463:166463:0100/000000.148707:ERROR:sandbox_linux.cc(377)] InitializeSandbox() called with multiple threads in process gpu-process.\n",
      "\u001b[32mAPI Key valid\u001b[0m\n",
      "\u001b[32mSaved API Key successfully!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Login to AIcrowd\n",
    "!pip install aicrowd-cli > /dev/null\n",
    "!aicrowd login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45c4c96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m                          Datasets for challenge #962                           \u001b[0m\r\n",
      "┌───┬────────────────────────────────┬────────────────────────────────┬────────┐\r\n",
      "│\u001b[1;35m \u001b[0m\u001b[1;35m#\u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35mTitle                         \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35mDescription                   \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;35m \u001b[0m\u001b[1;35m  Size\u001b[0m\u001b[1;35m \u001b[0m│\r\n",
      "├───┼────────────────────────────────┼────────────────────────────────┼────────┤\r\n",
      "│ 0 │ public_validation_set_2.0.tar… │ Validation Dataset (contains   │    59M │\r\n",
      "│   │                                │ 1000 images and 498            │        │\r\n",
      "│   │                                │ categories, with annotations)  │        │\r\n",
      "│ 1 │ public_test_release_2.0.tar.gz │ [Public] Testing Dataset       │   197M │\r\n",
      "│   │                                │ (contains 3000 images and 498  │        │\r\n",
      "│   │                                │ categories, without            │        │\r\n",
      "│   │                                │ annotations)                   │        │\r\n",
      "│ 2 │ public_training_set_release_2… │ Training Dataset (contains     │ 2.14GB │\r\n",
      "│   │                                │ 39962 images and 498           │        │\r\n",
      "│   │                                │ categories)                    │        │\r\n",
      "└───┴────────────────────────────────┴────────────────────────────────┴────────┘\r\n"
     ]
    }
   ],
   "source": [
    "# List dataset for this challenge\n",
    "!aicrowd dataset list -c food-recognition-benchmark-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f07ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "!aicrowd dataset download -c food-recognition-benchmark-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f813adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test dataset\n",
      "Extracting val dataset\n",
      "Extracting train dataset\n"
     ]
    }
   ],
   "source": [
    "# Create data directory\n",
    "!mkdir -p data/ data/train data/val data/test\n",
    "!echo \"Extracting test dataset\" && tar -xvf *test* -C data/test > /dev/null\n",
    "!echo \"Extracting val dataset\" &&  tar -xvf *val* -C data/val > /dev/null\n",
    "!echo \"Extracting train dataset\" &&  tar -xvf *train* -C data/train > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf7883d",
   "metadata": {},
   "source": [
    "# Processing Dataset - [ Train, Validation ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0a23ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to Activeloop.\r\n"
     ]
    }
   ],
   "source": [
    "# Login to activeloop if using Activeloop Storage (hub://.....)\n",
    "!activeloop login -u sainikhileshreddy -p VQaE8A2K3Sh2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b3a142a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/:\r\n",
      "images\r\n",
      "\r\n",
      "data/train/:\r\n",
      "annotations.json  images\r\n",
      "\r\n",
      "data/val/:\r\n",
      "annotations.json  images\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "838ae82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39962/39962 [21:29<00:00, 30.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations modified at data/train/new_annotations.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:04<00:00, 219.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations modified at data/val/new_annotations.json\n"
     ]
    }
   ],
   "source": [
    "# In the dataset summary (from first link), we see that there is mismatch in \n",
    "# image sizes. So we correct the mismatch before we move forward\n",
    "def fix_data(directory):\n",
    "    \n",
    "    annotations_path = os.path.join(directory, 'annotations.json')\n",
    "    annotations = json.load(open(annotations_path, 'r'))\n",
    "    for n, i in enumerate(tqdm((annotations['images']))):\n",
    "        image_path = os.path.join(directory, 'images', i[\"file_name\"])\n",
    "        img = Image.open(image_path)\n",
    "        if img.size[1] != i['height']:\n",
    "            annotations['images'][n]['height'] = img.shape[1]\n",
    "\n",
    "        if img.size[0] != i['width']:\n",
    "            annotations['images'][n]['width'] = img.shape[0]\n",
    "    \n",
    "    json_path = os.path.join(directory, 'new_annotations.json')\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(annotations, f)\n",
    "        print(f'Annotations modified at {json_path}')\n",
    "\n",
    "fix_data(os.path.join('data', 'train'))\n",
    "fix_data(os.path.join('data', 'val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "201f6f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "# Valid choices are 'train' and 'val'. \n",
    "# Testing is a special case at the end of the notebook\n",
    "data_type='train' \n",
    "\n",
    "# hub_path = 'hub://sainikhileshreddy/food-recognition-2022-{}'.format(data_type)\n",
    "hub_path = './{}'.format(data_type)\n",
    "\n",
    "# Specify dataset path\n",
    "# Set overwrite = True if you need to start over\n",
    "ds = hub.empty(hub_path, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "88101a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub.delete(hub_path, large_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a88eac92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=2.77s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "annotation_file = os.path.join(base_path, data_type, 'new_annotations.json')\n",
    "images_root = os.path.join(base_path, data_type, 'images')\n",
    "coco = COCO(annotation_file)\n",
    "category_info = coco.loadCats(coco.getCatIds())\n",
    "cat_names = [category['name'] for category in category_info]\n",
    "super_cat_names = list(set([category['supercategory'] for category in category_info]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e73a9842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 100 images\n",
      "Uploaded 200 images\n",
      "Uploaded 300 images\n",
      "Uploaded 400 images\n",
      "Uploaded 500 images\n",
      "Uploaded 600 images\n",
      "Uploaded 700 images\n",
      "Uploaded 800 images\n",
      "Uploaded 900 images\n",
      "Uploaded 1000 images\n",
      "Uploaded 1100 images\n",
      "Uploaded 1200 images\n",
      "Uploaded 1300 images\n",
      "Uploaded 1400 images\n",
      "Uploaded 1500 images\n",
      "Uploaded 1600 images\n",
      "Uploaded 1700 images\n",
      "Uploaded 1800 images\n",
      "Uploaded 1900 images\n",
      "Uploaded 2000 images\n",
      "Uploaded 2100 images\n",
      "Uploaded 2200 images\n",
      "Uploaded 2300 images\n",
      "Uploaded 2400 images\n",
      "Uploaded 2500 images\n",
      "Uploaded 2600 images\n",
      "Uploaded 2700 images\n",
      "Uploaded 2800 images\n",
      "Uploaded 2900 images\n",
      "Uploaded 3000 images\n",
      "Uploaded 3100 images\n",
      "Uploaded 3200 images\n",
      "Uploaded 3300 images\n",
      "Uploaded 3400 images\n",
      "Uploaded 3500 images\n",
      "Uploaded 3600 images\n",
      "Uploaded 3700 images\n",
      "Uploaded 3800 images\n",
      "Uploaded 3900 images\n",
      "Uploaded 4000 images\n",
      "Uploaded 4100 images\n",
      "Uploaded 4200 images\n",
      "Uploaded 4300 images\n",
      "Uploaded 4400 images\n",
      "Uploaded 4500 images\n",
      "Uploaded 4600 images\n",
      "Uploaded 4700 images\n",
      "Uploaded 4800 images\n",
      "Uploaded 4900 images\n",
      "Uploaded 5000 images\n",
      "Uploaded 5100 images\n",
      "Uploaded 5200 images\n",
      "Uploaded 5300 images\n",
      "Uploaded 5400 images\n",
      "Uploaded 5500 images\n",
      "Uploaded 5600 images\n",
      "Uploaded 5700 images\n",
      "Uploaded 5800 images\n",
      "Uploaded 5900 images\n",
      "Uploaded 6000 images\n",
      "Uploaded 6100 images\n",
      "Uploaded 6200 images\n",
      "Uploaded 6300 images\n",
      "Uploaded 6400 images\n",
      "Uploaded 6500 images\n",
      "Uploaded 6600 images\n",
      "Uploaded 6700 images\n",
      "Uploaded 6800 images\n",
      "Uploaded 6900 images\n",
      "Uploaded 7000 images\n",
      "Uploaded 7100 images\n",
      "Uploaded 7200 images\n",
      "Uploaded 7300 images\n",
      "Uploaded 7400 images\n",
      "Uploaded 7500 images\n",
      "Uploaded 7600 images\n",
      "Uploaded 7700 images\n",
      "Uploaded 7800 images\n",
      "Uploaded 7900 images\n",
      "Uploaded 8000 images\n",
      "Uploaded 8100 images\n",
      "Uploaded 8200 images\n",
      "Uploaded 8300 images\n",
      "Uploaded 8400 images\n",
      "Uploaded 8500 images\n",
      "Uploaded 8600 images\n",
      "Uploaded 8700 images\n",
      "Uploaded 8800 images\n",
      "Uploaded 8900 images\n",
      "Uploaded 9000 images\n",
      "Uploaded 9100 images\n",
      "Uploaded 9200 images\n",
      "Uploaded 9300 images\n",
      "Uploaded 9400 images\n",
      "Uploaded 9500 images\n",
      "Uploaded 9600 images\n",
      "Uploaded 9700 images\n",
      "Uploaded 9800 images\n",
      "Uploaded 9900 images\n",
      "Uploaded 10000 images\n",
      "Uploaded 10100 images\n",
      "Uploaded 10200 images\n",
      "Uploaded 10300 images\n",
      "Uploaded 10400 images\n",
      "Uploaded 10500 images\n",
      "Uploaded 10600 images\n",
      "Uploaded 10700 images\n",
      "Uploaded 10800 images\n",
      "Uploaded 10900 images\n",
      "Uploaded 11000 images\n",
      "Uploaded 11100 images\n",
      "Uploaded 11200 images\n",
      "Uploaded 11300 images\n",
      "Uploaded 11400 images\n",
      "Uploaded 11500 images\n",
      "Uploaded 11600 images\n",
      "Uploaded 11700 images\n",
      "Uploaded 11800 images\n",
      "Uploaded 11900 images\n",
      "Uploaded 12000 images\n",
      "Uploaded 12100 images\n",
      "Uploaded 12200 images\n",
      "Uploaded 12300 images\n",
      "Uploaded 12400 images\n",
      "Uploaded 12500 images\n",
      "Uploaded 12600 images\n",
      "Uploaded 12700 images\n",
      "Uploaded 12800 images\n",
      "Uploaded 12900 images\n",
      "Uploaded 13000 images\n",
      "Uploaded 13100 images\n",
      "Uploaded 13200 images\n",
      "Uploaded 13300 images\n",
      "Uploaded 13400 images\n",
      "Uploaded 13500 images\n",
      "Uploaded 13600 images\n",
      "Uploaded 13700 images\n",
      "Uploaded 13800 images\n",
      "Uploaded 13900 images\n",
      "Uploaded 14000 images\n",
      "Uploaded 14100 images\n",
      "Uploaded 14200 images\n",
      "Uploaded 14300 images\n",
      "Uploaded 14400 images\n",
      "Uploaded 14500 images\n",
      "Uploaded 14600 images\n",
      "Uploaded 14700 images\n",
      "Uploaded 14800 images\n",
      "Uploaded 14900 images\n",
      "Uploaded 15000 images\n",
      "Uploaded 15100 images\n",
      "Uploaded 15200 images\n",
      "Uploaded 15300 images\n",
      "Uploaded 15400 images\n",
      "Uploaded 15500 images\n",
      "Uploaded 15600 images\n",
      "Uploaded 15700 images\n",
      "Uploaded 15800 images\n",
      "Uploaded 15900 images\n",
      "Uploaded 16000 images\n",
      "Uploaded 16100 images\n",
      "Uploaded 16200 images\n",
      "Uploaded 16300 images\n",
      "Uploaded 16400 images\n",
      "Uploaded 16500 images\n",
      "Uploaded 16600 images\n",
      "Uploaded 16700 images\n",
      "Uploaded 16800 images\n",
      "Uploaded 16900 images\n",
      "Uploaded 17000 images\n",
      "Uploaded 17100 images\n",
      "Uploaded 17200 images\n",
      "Uploaded 17300 images\n",
      "Uploaded 17400 images\n",
      "Uploaded 17500 images\n",
      "Uploaded 17600 images\n",
      "Uploaded 17700 images\n",
      "Uploaded 17800 images\n",
      "Uploaded 17900 images\n",
      "Uploaded 18000 images\n",
      "Uploaded 18100 images\n",
      "Uploaded 18200 images\n",
      "Uploaded 18300 images\n",
      "Uploaded 18400 images\n",
      "Uploaded 18500 images\n",
      "Uploaded 18600 images\n",
      "Uploaded 18700 images\n",
      "Uploaded 18800 images\n",
      "Uploaded 18900 images\n",
      "Uploaded 19000 images\n",
      "Uploaded 19100 images\n",
      "Uploaded 19200 images\n",
      "Uploaded 19300 images\n",
      "Uploaded 19400 images\n",
      "Uploaded 19500 images\n",
      "Uploaded 19600 images\n",
      "Uploaded 19700 images\n",
      "Uploaded 19800 images\n",
      "Uploaded 19900 images\n",
      "Uploaded 20000 images\n",
      "Uploaded 20100 images\n",
      "Uploaded 20200 images\n",
      "Uploaded 20300 images\n",
      "Uploaded 20400 images\n",
      "Uploaded 20500 images\n",
      "Uploaded 20600 images\n",
      "Uploaded 20700 images\n",
      "Uploaded 20800 images\n",
      "Uploaded 20900 images\n",
      "Uploaded 21000 images\n",
      "Uploaded 21100 images\n",
      "Uploaded 21200 images\n",
      "Uploaded 21300 images\n",
      "Uploaded 21400 images\n",
      "Uploaded 21500 images\n",
      "Uploaded 21600 images\n",
      "Uploaded 21700 images\n",
      "Uploaded 21800 images\n",
      "Uploaded 21900 images\n",
      "Uploaded 22000 images\n",
      "Uploaded 22100 images\n",
      "Uploaded 22200 images\n",
      "Uploaded 22300 images\n",
      "Uploaded 22400 images\n",
      "Uploaded 22500 images\n",
      "Uploaded 22600 images\n",
      "Uploaded 22700 images\n",
      "Uploaded 22800 images\n",
      "Uploaded 22900 images\n",
      "Uploaded 23000 images\n",
      "Uploaded 23100 images\n",
      "Uploaded 23200 images\n",
      "Uploaded 23300 images\n",
      "Uploaded 23400 images\n",
      "Uploaded 23500 images\n",
      "Uploaded 23600 images\n",
      "Uploaded 23700 images\n",
      "Uploaded 23800 images\n",
      "Uploaded 23900 images\n",
      "Uploaded 24000 images\n",
      "Uploaded 24100 images\n",
      "Uploaded 24200 images\n",
      "Uploaded 24300 images\n",
      "Uploaded 24400 images\n",
      "Uploaded 24500 images\n",
      "Uploaded 24600 images\n",
      "Uploaded 24700 images\n",
      "Uploaded 24800 images\n",
      "Uploaded 24900 images\n",
      "Uploaded 25000 images\n",
      "Uploaded 25100 images\n",
      "Uploaded 25200 images\n",
      "Uploaded 25300 images\n",
      "Uploaded 25400 images\n",
      "Uploaded 25500 images\n",
      "Uploaded 25600 images\n",
      "Uploaded 25700 images\n",
      "Uploaded 25800 images\n",
      "Uploaded 25900 images\n",
      "Uploaded 26000 images\n",
      "Uploaded 26100 images\n",
      "Uploaded 26200 images\n",
      "Uploaded 26300 images\n",
      "Uploaded 26400 images\n",
      "Uploaded 26500 images\n",
      "Uploaded 26600 images\n",
      "Uploaded 26700 images\n",
      "Uploaded 26800 images\n",
      "Uploaded 26900 images\n",
      "Uploaded 27000 images\n",
      "Uploaded 27100 images\n",
      "Uploaded 27200 images\n",
      "Uploaded 27300 images\n",
      "Uploaded 27400 images\n",
      "Uploaded 27500 images\n",
      "Uploaded 27600 images\n",
      "Uploaded 27700 images\n",
      "Uploaded 27800 images\n",
      "Uploaded 27900 images\n",
      "Uploaded 28000 images\n",
      "Uploaded 28100 images\n",
      "Uploaded 28200 images\n",
      "Uploaded 28300 images\n",
      "Uploaded 28400 images\n",
      "Uploaded 28500 images\n",
      "Uploaded 28600 images\n",
      "Uploaded 28700 images\n",
      "Uploaded 28800 images\n",
      "Uploaded 28900 images\n",
      "Uploaded 29000 images\n",
      "Uploaded 29100 images\n",
      "Uploaded 29200 images\n",
      "Uploaded 29300 images\n",
      "Uploaded 29400 images\n",
      "Uploaded 29500 images\n",
      "Uploaded 29600 images\n",
      "Uploaded 29700 images\n",
      "Uploaded 29800 images\n",
      "Uploaded 29900 images\n",
      "Uploaded 30000 images\n",
      "Uploaded 30100 images\n",
      "Uploaded 30200 images\n",
      "Uploaded 30300 images\n",
      "Uploaded 30400 images\n",
      "Uploaded 30500 images\n",
      "Uploaded 30600 images\n",
      "Uploaded 30700 images\n",
      "Uploaded 30800 images\n",
      "Uploaded 30900 images\n",
      "Uploaded 31000 images\n",
      "Uploaded 31100 images\n",
      "Uploaded 31200 images\n",
      "Uploaded 31300 images\n",
      "Uploaded 31400 images\n",
      "Uploaded 31500 images\n",
      "Uploaded 31600 images\n",
      "Uploaded 31700 images\n",
      "Uploaded 31800 images\n",
      "Uploaded 31900 images\n",
      "Uploaded 32000 images\n",
      "Uploaded 32100 images\n",
      "Uploaded 32200 images\n",
      "Uploaded 32300 images\n",
      "Uploaded 32400 images\n",
      "Uploaded 32500 images\n",
      "Uploaded 32600 images\n",
      "Uploaded 32700 images\n",
      "Uploaded 32800 images\n",
      "Uploaded 32900 images\n",
      "Uploaded 33000 images\n",
      "Uploaded 33100 images\n",
      "Uploaded 33200 images\n",
      "Uploaded 33300 images\n",
      "Uploaded 33400 images\n",
      "Uploaded 33500 images\n",
      "Uploaded 33600 images\n",
      "Uploaded 33700 images\n",
      "Uploaded 33800 images\n",
      "Uploaded 33900 images\n",
      "Uploaded 34000 images\n",
      "Uploaded 34100 images\n",
      "Uploaded 34200 images\n",
      "Uploaded 34300 images\n",
      "Uploaded 34400 images\n",
      "Uploaded 34500 images\n",
      "Uploaded 34600 images\n",
      "Uploaded 34700 images\n",
      "Uploaded 34800 images\n",
      "Uploaded 34900 images\n",
      "Uploaded 35000 images\n",
      "Uploaded 35100 images\n",
      "Uploaded 35200 images\n",
      "Uploaded 35300 images\n",
      "Uploaded 35400 images\n",
      "Uploaded 35500 images\n",
      "Uploaded 35600 images\n",
      "Uploaded 35700 images\n",
      "Uploaded 35800 images\n",
      "Uploaded 35900 images\n",
      "Uploaded 36000 images\n",
      "Uploaded 36100 images\n",
      "Uploaded 36200 images\n",
      "Uploaded 36300 images\n",
      "Uploaded 36400 images\n",
      "Uploaded 36500 images\n",
      "Uploaded 36600 images\n",
      "Uploaded 36700 images\n",
      "Uploaded 36800 images\n",
      "Uploaded 36900 images\n",
      "Uploaded 37000 images\n",
      "Uploaded 37100 images\n",
      "Uploaded 37200 images\n",
      "Uploaded 37300 images\n",
      "Uploaded 37400 images\n",
      "Uploaded 37500 images\n",
      "Uploaded 37600 images\n",
      "Uploaded 37700 images\n",
      "Uploaded 37800 images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 37900 images\n",
      "Uploaded 38000 images\n",
      "Uploaded 38100 images\n",
      "Uploaded 38200 images\n",
      "Uploaded 38300 images\n",
      "Uploaded 38400 images\n",
      "Uploaded 38500 images\n",
      "Uploaded 38600 images\n",
      "Uploaded 38700 images\n",
      "Uploaded 38800 images\n",
      "Uploaded 38900 images\n",
      "Uploaded 39000 images\n",
      "Uploaded 39100 images\n",
      "Uploaded 39200 images\n",
      "Uploaded 39300 images\n",
      "Uploaded 39400 images\n",
      "Uploaded 39500 images\n",
      "Uploaded 39600 images\n",
      "Uploaded 39700 images\n",
      "Uploaded 39800 images\n",
      "Uploaded 39900 images\n",
      "Finished\n",
      "Upload took 1593.4238450527191 seconds for 39962 images\n"
     ]
    }
   ],
   "source": [
    "img_ids = sorted(coco.getImgIds()) # Image ids for uploading\n",
    "count = 0\n",
    "\n",
    "start_time = time.time()\n",
    "with ds:\n",
    "    \n",
    "    ## ---- Create Tensors ----- ##\n",
    "    ds.create_tensor('images', htype = 'image', sample_compression = 'jpg')\n",
    "    ds.create_tensor('images_meta', htype = 'json')\n",
    "    ds.create_tensor('masks', htype = 'binary_mask', sample_compression = 'lz4')\n",
    "    ds.create_tensor('boxes', htype = 'bbox')\n",
    "    ds.create_tensor('categories', htype = 'class_label', class_names = cat_names)\n",
    "    ds.create_tensor('super_categories', htype = 'class_label', class_names = super_cat_names)\n",
    "    ds.create_tensor('areas', dtype = 'uint32')\n",
    "    ds.create_tensor('iscrowds', dtype = 'bool')\n",
    "    \n",
    "    ## ---- Iterate through each image and upload data ----- ##\n",
    "    for img_id in img_ids:\n",
    "        ann_ids = coco.getAnnIds(img_id)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "        \n",
    "        img_coco = coco.loadImgs(img_id)[0]\n",
    "        img_fn = os.path.join(images_root, img_coco['file_name'])\n",
    "        img = Image.open(img_fn)\n",
    "        dims = img.size\n",
    "        \n",
    "        \n",
    "        #Iterate through annotations and parse each\n",
    "        \n",
    "        #First Create empty arrays for all annotations\n",
    "        masks = np.zeros((dims[1], dims[0], len(anns)))\n",
    "        boxes = np.zeros((len(anns),4))\n",
    "        categories = np.zeros((len(anns)))\n",
    "        supercats = np.zeros((len(anns)))\n",
    "        areas = np.zeros((len(anns)))\n",
    "        iscrowds = np.zeros((len(anns)))\n",
    "        supercats = np.zeros((len(anns)))\n",
    "        \n",
    "        #Then populate the arrays with the annotations data\n",
    "        for i, ann in enumerate(anns):\n",
    "            mask = coco.annToMask(ann) #Convert annotation to mask\n",
    "            masks[:,:,i] = mask\n",
    "            boxes[i,:] = ann['bbox']\n",
    "            \n",
    "            # Do a brute force search and make no assumptions between order of relationship of category ids\n",
    "            categories[i] = cat_names.index([category_info[i]['name'] for i in range(len(category_info)) if category_info[i]['id']==ann['category_id']][0])\n",
    "            supercats[i] = super_cat_names.index([category_info[i]['supercategory'] for i in range(len(category_info)) if category_info[i]['id']==ann['category_id']][0])\n",
    "            \n",
    "            areas[i] = ann['area']\n",
    "            iscrowds[i] = ann['iscrowd']            \n",
    "\n",
    "            if 'segmentation' not in ann:\n",
    "                print('--- No segmentation found in annotations. ---')\n",
    "                print('Annotation length: {}'.format(len(anns)))\n",
    "                print('--- image id: {} ---'.format(img_id))\n",
    "                \n",
    "        \n",
    "        #Append data to hub. Only do this after all annotations have been parsed.\n",
    "        try:\n",
    "            ds.images.append(hub.read(img_fn, verify = True))\n",
    "            ds.images_meta.append(img_coco)\n",
    "            ds.masks.append(masks.astype('bool'))\n",
    "            ds.boxes.append(boxes.astype('float32'))\n",
    "            ds.categories.append(categories.astype('uint32'))\n",
    "            ds.super_categories.append(supercats.astype('uint32'))\n",
    "            ds.areas.append(areas.astype('uint32'))\n",
    "            ds.iscrowds.append(iscrowds.astype('bool'))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        if count > 0 and count%100==0:\n",
    "            print('Uploaded {} images'.format(count))\n",
    "        \n",
    "#         if count > 10:\n",
    "#             break;\n",
    "            \n",
    "        count+=1\n",
    "    print('Finished')\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "print('Upload took {} seconds for {} images'.format(end_time-start_time, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b38c6b",
   "metadata": {},
   "source": [
    "# Processing Dataset - [ Test ] - Special Case COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0b96d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "# Special case - COCO Test dataset without annotations\n",
    "data_type='test' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "42f61ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hub_path = 'hub://sainikhileshreddy/food-recognition-2022-{}'.format(data_type)\n",
    "hub_path = './{}'.format(data_type)\n",
    "\n",
    "# Specify dataset path\n",
    "# Set overwrite = True if you need to start over\n",
    "ds = hub.empty(hub_path, overwrite = True)\n",
    "\n",
    "images_path = glob(os.path.join(base_path, data_type, 'images', '*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e89a413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hub.delete(hub_path, large_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a61ef411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload took 12.611701965332031 seconds for 2999 images\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "with ds:\n",
    "    \n",
    "    ds.create_tensor('images', htype = 'image', sample_compression = 'jpg')\n",
    "    ds.create_tensor('images_meta', htype = 'json')\n",
    "    \n",
    "    for (index, image_path) in enumerate(images_path):\n",
    "\n",
    "        image_name = image_path.split('/')[-1]\n",
    "        image_id = image_name.split('.')[0]\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        (width, height) = image.size\n",
    "        meta = {\n",
    "            'id' : image_id,\n",
    "            'file_name' : image_name,\n",
    "            'width' : width,\n",
    "            'height' : height\n",
    "        }\n",
    "        \n",
    "        ds.images.append(hub.read(image_path))\n",
    "        ds.images_meta.append(meta)\n",
    "        # print(f'{index} -> {image_name}')\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print('Upload took {} seconds for {} images'.format(end_time-start_time, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272df11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaeec03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285bfc83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3411f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
