{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# How to train the dataset?","metadata":{}},{"cell_type":"code","source":"# Lets first install hub\nfrom IPython.display import clear_output\n!pip install hub\nclear_output()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-02-19T18:15:23.752055Z","iopub.execute_input":"2022-02-19T18:15:23.752447Z","iopub.status.idle":"2022-02-19T18:16:08.604498Z","shell.execute_reply.started":"2022-02-19T18:15:23.752337Z","shell.execute_reply":"2022-02-19T18:16:08.603430Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Import necessary packages\nimport hub\nimport torch\nfrom torchvision import transforms\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom matplotlib import pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-02-19T18:16:08.607133Z","iopub.execute_input":"2022-02-19T18:16:08.607476Z","iopub.status.idle":"2022-02-19T18:16:12.801874Z","shell.execute_reply.started":"2022-02-19T18:16:08.607432Z","shell.execute_reply":"2022-02-19T18:16:12.800918Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"ds_train = hub.load('/kaggle/input/food-recognition-2022/hub/train')\nds_val = hub.load('/kaggle/input/food-recognition-2022/hub/val')\nds_test = hub.load('/kaggle/input/food-recognition-2022/hub/test')","metadata":{"execution":{"iopub.status.busy":"2022-02-19T18:17:23.664568Z","iopub.execute_input":"2022-02-19T18:17:23.665648Z","iopub.status.idle":"2022-02-19T18:17:23.920307Z","shell.execute_reply.started":"2022-02-19T18:17:23.665597Z","shell.execute_reply":"2022-02-19T18:17:23.919469Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"global class_labels;\nclass_labels = ds_train.categories.info.class_names","metadata":{"execution":{"iopub.status.busy":"2022-02-19T18:17:26.118655Z","iopub.execute_input":"2022-02-19T18:17:26.119344Z","iopub.status.idle":"2022-02-19T18:17:26.131735Z","shell.execute_reply.started":"2022-02-19T18:17:26.119288Z","shell.execute_reply":"2022-02-19T18:17:26.130926Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def transform(data):\n    image, bboxes = data['images'], data['boxes']\n    masks, categories = data['masks'], data['categories']\n\n    transform_all = A.Compose(\n        [\n            A.CenterCrop(100, 100, p=1),\n            ToTensorV2(),\n        ],\n        bbox_params={\n            'format':'coco', \n            'label_fields': ['class_labels']\n        }\n    )\n\n    transformed = transform_all(\n        image=image,\n        mask=masks,\n        bboxes=bboxes,\n        class_labels=categories,\n    )\n\n    image = transformed['image']\n    boxes = transformed['bboxes']\n    masks = transformed['mask']\n    categories = transformed['class_labels']\n    \n    return image, bboxes, masks, categories;\n\ndef collate_fn(batch):    \n    return {\n        \"images\" : torch.stack([x[0] for x in batch]), \n        \"boxes\" : [torch.tensor(x[1]) for x in batch],\n        \"masks\" : [x[2] for x in batch],\n        \"categories\" : [torch.tensor(x[3]) for x in batch]\n    }","metadata":{"execution":{"iopub.status.busy":"2022-02-19T18:19:34.645294Z","iopub.execute_input":"2022-02-19T18:19:34.645917Z","iopub.status.idle":"2022-02-19T18:19:34.655798Z","shell.execute_reply.started":"2022-02-19T18:19:34.645879Z","shell.execute_reply":"2022-02-19T18:19:34.654871Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataloader = ds_train.pytorch(num_workers = 0,\n                        batch_size = 1,\n                        transform = transform,\n                        tensors = ['images', 'boxes', 'masks', 'categories'],\n                        collate_fn = collate_fn,) \n\nfor batch in dataloader:\n    break;","metadata":{"execution":{"iopub.status.busy":"2022-02-19T18:19:35.077231Z","iopub.execute_input":"2022-02-19T18:19:35.078080Z","iopub.status.idle":"2022-02-19T18:19:35.177389Z","shell.execute_reply.started":"2022-02-19T18:19:35.078026Z","shell.execute_reply":"2022-02-19T18:19:35.176281Z"},"trusted":true},"execution_count":10,"outputs":[]}]}